text,summary,processed_text
"MULTI-SCALECROPPINGMECHANISMFORREMOTESENSINGIMAGECAPTIONING XuetingZhang1,QiWang1,ShangdongChen2,XuelongLi1* 1SchoolofComputerScienceandCenterforOPTicalIMageryAnalysisandLearning(OPTIMAL), NorthwesternPolytechnicalUniversity,Xian710072,Shaanxi,P.R.China. 2SchoolofInformationScienceandTechnology, NorthwestUniversity,Xian710072,Shaanxi,P.R.China. ABSTRACT Imagecaptioning[3]isacomprehensivetaskwhichcom- binescomputervisionandnaturallanguageprocessing.Since Withtherapiddevelopmentofartificialsatellite,alargenum- that encoder-decoder based method [4] can automaticallty ber of high resolution remote sensing images can be easily learn the hign-level semantic features and dig their textual obtained now. Recently, remote sensing image captioning, relationships, it has dominated the field of image caption- whichaimstogenerateaccurateandconcisedescriptivesen- ing with the best perpormance. The encoder process aims tences for remote sensing images, has been promoted by to represent an image with a feature map/vector by using template-based model and encoder-decoder model with sev- Convolutional Neural Networks (CNNs), while in decoder eral related datasets released. Based on an encoder-decoder process the feature map/vector is decoded into a sentence model,weproposeatrainingmechanismofmulti-scalecrop- by a sequence model, such as Recurrent Neural Networks pingforremotesensingimagecaptioninginthispaper,which (RNNs) and Long-Short Term Memory networks (LSTM) canextractmorefine-grainedinformationfromremotesens- [5]. This type of methods usually learn a large amount of ingimagesandenhancethegeneralizationperformanceofthe embeddedspaceforimagesandcaptions. Becausethereare basemodel. TheexperimentalresultsontwodatasetsUCM- no strict grammatical constraints, the system can generate captionsandSydney-captionsdemonstratethattheproposed relativelynewtextualdescriptionsforinputimages. approach availably improves the performances in describing highresolutionremotesensingimages. Correspondingly, some researches recently have been studied in remote sensing image captioning. Qu et al. [6] IndexTerms Remotesensingimage,imagecaptioning, firstly propose a deep multi-modal neural network model to encoder-decoder,multi-scalecropping solvetheproblemofunderstandingHSRremotesensingim- agesatthesemanticlevel,thenShietal.[7]presentaremote 1. INTRODUCTION sensingimagecaptioningframeworkbyleveragingtherecent techniquesofdeeplearningandfullyconvolutionalnetworks. Benefited from the rapid development of deep learning, re- For the former, different CNN architectures with RNN or cently, many researches in the field of remote sensing have LSTM are combined to generate meaningful sentences for beengreatlypromoted,includingobjectdetection,sceneclas- remotesensingimages.Whileforthelatter,atemplate-based sification [1] [2], semantic segmentation and so on. These model is applied to generate concise descriptions. Further- tasksmainlyexploretheattributesofvisualfeaturesfromthe more, based on a multimodal model, attention mechanism remote sensing images such as category, width, height and is introduced by Lu et al [8]. And both the handcrafted and others.Forthetaskofremotesensingimagecaptioning,how- deepfeaturesareutilizedinthismethod. ever, it has to further dig the relationship between these at- However,therearemanyproblemsneedtobesolved.For tributesanddescribeitwithflexiblesentencesinhumanlan- example, it is quite significant to explore how to reduce the guage. Tomakethemostoftheinformationinremotesens- overfitting problem of the model with the limit of training ingimages,remotesensingimagecaptioningisabletoextract samples. Inthefieldofimageclassification,tencropsmech- boththevisualandthecontextfeaturesfromanimage,which anism [9] is introduced to reduce the overfitting problem in canhelppeopleintuitivelyunderstandthecontentofremote thetrainingstage,whichisaneffectivemethodfordataargu- sensingimagesonasemanticlevel.Ithasawiderangeofap- mentation. Besides,multi-scaletraining[10]isacommonly plicationprospectsinmanydomainssuchasimageretrieval, used method in the field of object detection. Inspired by resourceinvestigation,disasterdetectionandmilitaryintelli- thesemethods,weproposeamulti-scalecroppingmechanism gencegeneration. forremotesensingimagecaptiongeneration, combiningten CorrespondingAuthor. cropswithmulti-scaletraining. Theoverallframeworkwith 978-1-5386-9154-0/19/$31.00 2019 IEEE 10039 IGARSS 2019 Authorized licensed use limited to: University of Florida. Downloaded on March 27,2024 at 23:22:37 UTC from IEEE Xplore. Restrictions apply. scale 1 resize Randomly Airplanes with scale 2 resize selected LSTM different size are CNN stopped at the airport. .. . .. . Sentence Image scale n resize Feature Vector Fig.1.Theframeworkoftheproposedmethod. theproposedmethodisshowninFig. 1. Themaincontribu- tionsofthispaperaresummarizedasfollows: d(cid:48) =ds (1) 1. A significant training mechanism of multi-scale crop- In this paper, d is 256 and S is set as [1.0, 0.875, 0.66]. ping for remote sensing image caption generation is Thus the range of d(cid:48) is [256, 224, 169]. Obviously, d(cid:48) is no proposed in this paper. The proposed training mecha- larger than d. Motivated by Tencrop, the patch is randomly nismcanimprovetheperformanceofimagecaptioning cropped from the five corners (upper left, lower left, upper withtheeffectofreducingtheoverfittingproblem. right,lowerrightandthecenter)andtheflippedfivecorners of the images. For each image, there are 22 (10 x 2 + 2) 2. Basedontheencoder-decoderframework,wetrainand possiblecroppingpaths.Thenthecroppedpatchwithvarious testdifferentcombinedmodelsofCNNsandLSTMon sizeisresizedto224x224beforebeingsenttotheencoder- twodatasetsUCM-captionsandSydney-captions. decoder model. Thus the cropping mechanism can provide 3. Theabundantexpermentialresultsprovetheeffective- variouscroppedpatchesP i (i=1,...,10)fromeachtraining ness of the proposed apporach for remote sensing im- image,whichcanimprovethegeneralizationofthemodel. agecaptioning. 2.2. Encoder-DecoderFramework 2. METHODOLOGY Togeneratemorenovelsentencesforremotesensingimages, ourapproachismainlybasedonthepopularencoder-decoder TheoverviewofwholeframeworkisshowninFig.1.Andthe framework,whichisdividedintotwostages:imagerepresen- structureoftheproposedmethodmainlycontainstwoparts: tation and sentence generation. In more detail, the encoder a multi-scale cropping mechanism and an encoder-decoder process encodes an image into a fixed-length feature vector, basedframework.Beforebeinginputintoanencoder-decoder while the decoder process aims to decode the feature vector framework,thegivenimagesneedtobeprocessedbyamulti- intoameaningfulsentence. scalecroppingmechanism. 2.1. Multi-scaleCropping 2.2.1. ImageReresentation Noting that the effective feature extraction is critical to the With the explosive development of deep learning and com- task of remote sensing image captioning, we introduce a puter vision, extracting features from images by learning multi-scalecroppingtrainingmechanismtoimprovethegen- based method has gradually gained popularity [11]. Due to eralizationoffeaturerepresentation. theexcellentabilityofautomaticallyextractingadvancedfea- AsshowninFig.1,theinputoftheframeworkisanimage tureswithfewerparameters,ConvolutionalNeuralNetworks thatisresizedtodxd. Weneedtoselectanpatchofd(cid:48) xd(cid:48) (CNNs) are introduced here for image representation. By fromtheimagethroughthemethodofmulti-scalecropping. replacingthelastfullyconnectedlayer,threedeepCNNsare Firstly,scalesisrandomlypickedupfromascalelistS that usedtorepresentthecroppedimageswithafixed-lengthvec- issetmanuallyinadvance. AndalltheelementsofS areno tor,whicharepre-trainedonImageNetdataset. Considering largerthan1.0. Themathematicalrelationshipofd,d(cid:48) ands theimagespreprocessedbythemulti-scalecroppingmecha- is: nism have been randomly cropped into different sizes, both 10040 Authorized licensed use limited to: University of Florida. Downloaded on March 27,2024 at 23:22:37 UTC from IEEE Xplore. Restrictions apply. Table 1. PERFORMANCES OF THE MULTI-SCALE Table 2. PERFORMANCES OF THE MULTI-SCALE CROPPING MECHANISM FOR REMOTE SENSING IM- CROPPING MECHANIASM FOR REMOTE SENSING AGECAPTIONINGONTHEUCM-CAPTIONSDATASET. IMAGE CAPTIONING ON THE SYDNEY-CAPTIONS B-NISBLEUSCOREFORN-GRAM. DATASET.B-NISBLEUSCOREFORN-GRAM. Model Scale B-1 B-2 B-3 B-4 Model Scale B-1 B-2 B-3 B-4 [s ] 57.1 50.5 44.6 38.3 [s ] 54.9 45.0 39.3 31.9 1 1 VGG-16 [s ,s ] 58.0 50.7 45.2 39.5 VGG-16 [s ,s ] 56.3 48.1 41.9 33.7 1 2 1 2 [s 1,s 2,s 3] 59.4 51.4 46.3 41.6 [s 1,s 2,s 3] 57.6 49.4 42.5 35.8 [s 1] 54.5 46.9 41.8 36.4 [s 1] 58.2 51.6 45.5 39.4 Inception-ResNetV2 [s 1,s 2] 54.8 48.5 43.3 37.8 Inception-ResNetV2 [s 1,s 2] 59.7 52.3 46.9 41.7 [s 1,s 2,s 3] 56.7 49.7 44.2 38.8 [s 1,s 2,s 3] 60.9 53.4 47.3 41.7 [s 1] 58.7 52.3 47.1 42.1 [s 1] 58.8 51.5 44.7 38.2 ResNet-152 [s 1,s 2] 59.1 52.6 47.1 42.4 ResNet-152 [s 1,s 2] 60.5 52.3 45.1 38.3 [s 1,s 2,s 3] 59.4 53.2 48.1 42.9 [s 1,s 2,s 3] 61.5 54.0 47.3 40.0 theglobalandlocalfeaturescanbeobtainedbytheCNN. 3. EXPERIMENTS v =CNN(P ) (2) 0 i In this section, we first give an introduction to the datasets Asshowninformula(2),eachpatchP istransferedinto and the metrics for experiments. Then some details of the i CNN, and then a fixed-length feature vector v is extracted experimentssetuparegiven. Finally,theperformanceofex- 0 fromit. perimentswithdifferentCNNsontwodatasetsarecompared toverifythegeneralizationcapabilitiesofourmethod. 2.2.2. SentencesGeneration 3.1. DatasetsandMetrics To generate accurate descriptive sentences for remote sens- ingimages,Long-ShortTermMemorynetworks (LSTM)[5] In experiments, two datasets of remote sensing image cap- isappliedinthecaptioningdecodingstage.Byusinggatesto tioning, UCM-captions and Sydney-captions, are used to controlthetransmissionofnetworkinformation,LSTMisde- evaluate the performance of different architectures with the signed to solve the long-term dependency problem in RNN. differentcroppingscales. TheUCM-captionsdatasetispro- The core of LSTM is three gates, including forgotten gate, vided by [6], which consists of 21 classes with 100 iamges inputgate,andoutputgate. LSTMfirstdecideswhichinfor- for each class. Each image is 256  256 pixels and the mationtodiscardthroughtheforgottengate. Thenbasedon resolution is 0.3048m. Based on the Sydney Data Set, the the input gate, it determines the values we are going to up- Sydney-captionsisalsoproposedin[6],whichcontains2329 date. Meanwhile,thetanhlayerisusedtogeneratecandidate imageswith7classes. Forbothtwodatasets, fivesentences valuesthatcanbeaddedtothenetworkstate. Afterthat,the aregiventodescribeeachimage. outputlayercangetthefinaloutputstatebyfiltering. Inaddition,acommonlyusedmetricforimagecaptioning In the time t=1, the feature vector v is transferred to i.e.BLEU[12]isutilizedtoevaluatethequalityofthegener- 0 LSTM. When the t-th word is generated, we can represent atedcaptions.Asameasureofsimilaritybasedonaccuracy,it theprocessasfollows: isfirstproposedin[12]toevaluatethetaskofmachinetrans- lation. Indetail,itisabletoanalyzetheconsistencybetween s={w ,...,w ,...,w },t{0...N} (3) 1 t N n-gramoccurrencesincandidateandreferencesentences. h =g(h ,v ,w ) (4) t t1 0 t1 p =softmax(h ) (5) 3.2. Setup t t whereh representsthehiddenstateofLSTMattimet,and Based on the encoder-decoder framework, we train and test t w isthecorrespondingwordinthecaptions. Specially,g() our method with three CNN architectures in the encoding t denotestheprocessofLSTM.Aftergoingthroughasoftmax stage, including VGG-16, Inception-ResNetV2 and ResNet- fuction,wecangettheprobabilityofthenextwordappearing 152[13]. Inthedecodingprocess,anLSTMisusedtogen- i.e. p . Thefinalgoalofthisstepistominimizethenegative eratetheeffectivesentences. AsforLSTM,thedimensionof t likelihoodfunctionoftargetsentences,namelyLoss. wordembeddingandhiddenstatearesetto512and512,re- spectively. And the number of layers in LSTM is one layer. N (cid:88) WeuseStochasticGradientDescent(SGD)withthelearning Loss= logp (w ) (6) t t rateof0.0001tooptimizethewholemodel. t=1 10041 Authorized licensed use limited to: University of Florida. Downloaded on March 27,2024 at 23:22:37 UTC from IEEE Xplore. Restrictions apply. classification, IEEE Transactions on Geoscience and RemoteSensing,vol.57,no.2,pp.911923,2019. [3] B. Qu, X. Li, D. Tao, and X. Lu, Deep semantic un- derstanding of high resolution remote sensing image, in International Conference on Computer, Information (a) A white air-(b) Lotsofhouses(c) The waves (d) Green plants planeisstoppedatarranged neatly slapping a white flourish on both andTelecommunicationSystems,2016,pp.124128. theairport. and a road goes sand beach over banksoftheriver. throughthem. andoveragain. [4] O.Vinyals,A.Toshev,S.Bengio,andD.Erhan, Show and tell: A neural image caption generator, in IEEE Fig.2.Theresultsoftestimagesandcorespondinggenerated Conference on Computer Vision and Pattern Recogni- captions. tion,2015,pp.31563164. [5] S. Hochreiter and J. Schmidhuber, Long short-term 3.3. ResultsandAnalysis memory, Neuralcomputation,vol.9,no.8,pp.1735 1780,1997. Table1andTable2showtheexperimentalresultsofthetwo datasetswithdifferentCNNarchitectures,respectively. Not- [6] B. Qu, X. Li, D. Tao, and X. Lu, Deep semantic un- ingthats 1,s 2,s 3 respectivelydenotethescaleof1.0, 0.875 derstanding of high resolution remote sensing image, and 0.66. From the results we can find that the evaluation in International Conference on Computer, Information scores on both UCM-captions and Sydney-captions with all andTelecommunicationSystems,2016,pp.124128. the CNN architectures are getting higher, with the selected scales increasing. And the Resnet-152 is the best CNN ar- [7] Z. Shi and Z. Zou, Can a machine generate human- chitectureforencodingprocessbetweenallthearchitectures likelanguagedescriptionsforaremotesensingimage?, inexperiments. Theabundantexperimentalresultsprovethe IEEETransactionsonGeoscienceandRemoteSensing, effectiveness of the proposed Multi-Scale Cropping Mecha- vol.55,no.6,pp.36233634,2017. nism. [8] X.Lu,B.Wang,X.Zheng,andX.Li, Exploringmod- els and data for remote sensing image caption genera- 4. CONCLUSION tion, IEEE Transactions on Geoscience and Remote Sensing,vol.56,no.4,pp.21832195,2018. Inthispaper, weproposeamulti-scalecroppingmechanism for training, which can extract advanced semantic features [9] A. Krizhevsky, I. Sutskever, and G. E. Hinton, Ima- fromimagessothatitcangeneratemeaningfulsentencesfor genetclassificationwithdeepconvolutionalneuralnet- the task of remote sensing image captioning. Based on an works, in International Conference on Neural Infor- popular encoder-decoder framework, three CNNs combined mationProcessingSystems,2012,pp.10971105. withLSTMarecomparedtovalidatethegeneralizationper- formanceofourmethod.Andtheexperimentalresultsontwo [10] K.He,X.Zhang,S.Ren,andJ.Sun, Spatialpyramid datasetsshowtheeffectivenessoftheproposedmethod. poolingindeepconvolutionalnetworksforvisualrecog- nition,IEEETransactionsonPatternAnalysisandMa- chineIntelligence,vol.37,no.9,pp.19041916,2015. 5. ACKNOWLEDGMENT [11] J.Yu,C.Zhu,J.Zhang,Q.Huang,andD.Tao, Spatial This work was supported by the National Natural Science pyramid-enhancedNetVLADwithandweightedtriplet Foundation of China under Grant U1864204 and 61773316, lossforplacerecognition, IEEETransactionsonNeu- NaturalScienceFoundationofShaanxiProvinceunderGrant ralNetworksandLearningSystems,2019. 2018KJXX-024,andProjectofSpecialZoneforNationalDe- fenseScienceandTechnologyInnovation. [12] K.Papineni,S.Roukos,T.Ward,andW.J.Zhu, Bleu: A method for automatic evaluation of machine trans- lation, in Association for Computational Linguistics, 6. REFERENCES 2002,pp.311318. [1] Q.Wang,S.Liu,J.Chanussot,andX.Li,Sceneclassi- [13] K. He, X. Zhang, S. Ren, and J. Sun, Deep residual ficationwithrecurrentattentionofVHRremotesensing learning for image recognition, in IEEE Conference images,IEEETransactionsonGeoscienceandRemote onComputerVisionandPatternRecognition,2016,pp. Sensing,,no.99,pp.113,2018. 770778. [2] Q.Wang,X.He,andX.Li,Localityandstructureregu- larizedlowrankrepresentationforhyperspectralimage 10042 Authorized licensed use limited to: University of Florida. Downloaded on March 27,2024 at 23:22:37 UTC from IEEE Xplore. Restrictions apply.","in this paper , we propose a novel method for remote sensing image captioning . the method is based on a multi - modal neural network model , which is used to generate meaningful sentences . in this method , a feature map/vector is decoded into a sentence model with sev - convolutional neural network ( cNNs ) , while in decoder eral related datasets released . this method is applied to generate a large amount of ingimages . it is shown that the sydney-caption is a powerful tool for generating meaningful sentences for a given image . in this paper , we introduce a puter vision , extracting features from images by learning multi-scalecroppingtrainingmechanismtoimprovethegen-based method . based on the eigenvalues of the encoder , a set of encodings is derived , and a recursive method is developed . it is shown that , in the case of a fixed-length feature vector , it is possible to extract features from a given image by a multi - scalecropping mechanism . in this case , the recurrence - based method is used to extract the feature vector framework  in this paper , we present a new method for analyzing the performance of remote sensing images . the method is based on the encoding t denotestheprocessofLSTMattimet , which is used to controlthetransmissionofnetworkinformation . it is shown that the t -th word is derived from a symplectic , asymmetric , and asymmetry - based . we also show that , in the equivalence , the corresponding eigenvalues are derived . _ key words : _ _ @xmath0 . in this paper , we propose a method for generating a machine based on a multi - scalecroppingmechanism for remote sensing image captioning . the method is based upon a non - gaussian recurrence , which is characterized by a symmetries . we show that the method can be applied to a wide range of arbitrary scales , such as the eigenvalues of the corresponding machine , and the entanglement of the machine . in this work , it is shown that the algorithm can be used as a tool for obtaining a higher - order",multi scalecroppingmechanismforremotesensingimagecaptioning northwesternpolytechnicaluniversity northwestuniversity abstract withtherapiddevelopmentofartificialsatellite encoder decoder base method automaticallty ber high resolution remote sensing image easily learn hign level semantic feature dig textual obtain recently remote sense image captioning relationship dominate field image ing good perpormance encoder process aim tence remote sense image promote represent image feature map vector template base model encoder decoder model convolutional neural network cnns decoder eral relate dataset release base encoder decoder process feature map vector decode sentence model weproposeatrainingmechanismofmulti sequence model recurrent neural network pingforremotesensingimagecaptioninginthispaper rnns long short term memory network lstm canextractmorefine type method usually learn large ingimagesandenhancethegeneralizationperformanceofthe embeddedspaceforimagesandcaption becausethereare basemodel strict grammatical constraint system generate captionsandsydney captionsdemonstratethatthepropose relativelynewtextualdescriptionsforinputimage approach availably improve performance describe highresolutionremotesensingimage correspondingly research recently study remote sense image captioning qu et al indexterm remotesensingimage imagecaptioning firstly propose deep multi modal neural network model encoder decoder multi scalecropping agesatthesemanticlevel introduction sensingimagecaptioningframeworkbyleveragingtherecent techniquesofdeeplearningandfullyconvolutionalnetwork benefit rapid development deep learning different cnn architecture rnn cently research field remote sensing lstm combine generate meaningful sentence beengreatlypromote includingobjectdetection atemplate base sification semantic segmentation model apply generate concise description tasksmainlyexploretheattributesofvisualfeaturesfromthe base multimodal model attention mechanism remote sensing image category width height introduce lu et al handcrafted deepfeaturesareutilizedinthismethod dig relationship example significant explore reduce guage overfitte problem model limit training ingimage remotesensingimagecaptioningisabletoextract sample inthefieldofimageclassification boththevisualandthecontextfeaturesfromanimage anism introduce reduce overfitte problem canhelppeopleintuitivelyunderstandthecontentofremote thetrainingstage mentation multi plicationprospectsinmanydomainssuchasimageretrieval method field object detection inspire resourceinvestigation thesemethod weproposeamulti scalecroppingmechanism gencegeneration forremotesensingimagecaptiongeneration combiningten correspondingauthor cropswithmulti scaletraining theoverallframeworkwith ieee igarss authorize license use limit university florida download march utc ieee xplore restriction apply scale resize randomly airplane scale resize select lstm different size cnn stop airport sentence image scale n resize feature vector theproposedmethodisshowninfig tionsofthispaperaresummarizedasfollow ds significant training mechanism multi scale paper d s set ping remote sense image caption generation range obviously propose paper propose training large motivate tencrop patch randomly nismcanimprovetheperformanceofimagecaptione crop corner upper left lower left upper withtheeffectofreducingtheoverfittingproblem right image image x basedontheencoder decoderframework wetrainand testdifferentcombinedmodelsofcnnsandlstmon twodatasetsucm captionsandsydney caption decoder model cropping mechanism provide variouscroppedpatchesp ness propose apporach remote sense image whichcanimprovethegeneralizationofthemodel agecaptione encoder decoderframework methodology togeneratemorenovelsentencesforremotesensingimage ourapproachismainlybasedonthepopularencoder decoder framework whichisdividedintotwostage structureoftheproposedmethodmainlycontainstwopart tation sentence generation detail encoder multi scale cropping mechanism encoder decoder process encode image fix length feature vector decoder decoder process aim decode feature vector framework intoameaningfulsentence scalecroppingmechanism multi scalecroppe imagereresentation note effective feature extraction critical explosive development deep learning task remote sense image captioning introduce puter vision extract feature image learn multi base method gradually gain popularity eralizationoffeaturerepresentation tureswithfewerparameter convolutionalneuralnetwork thatisresizedtodxd cnns introduce image representation fromtheimagethroughthemethodofmulti scalecropping replacingthelastfullyconnectedlayer threedeepcnnsare firstly scalesisrandomlypickedupfromascalelist usedtorepresentthecroppedimageswithafixed issetmanuallyinadvance andalltheelementsofs areno tor whicharepre trainedonimagenetdataset consider themathematicalrelationshipofd and theimagespreprocessedbythemulti nism randomly crop different size authorize license use limit university florida download march utc ieee xplore restriction apply table performance multi scale table performance multi scale cropping mechanism remote sensing cropping mechaniasm remote sense agecaptioningontheucm captionsdataset image captioning sydney captions b nisbleuscoreforn gram nisbleuscoreforn gram model scale model scale s s s s s s s s s s inception s inception s s s s s s s s s theglobalandlocalfeaturescanbeobtainedbythecnn experiment v section introduction dataset istransferedinto metric experiment detail cnn fix length feature vector v extract experimentssetuparegiven finally fromit perimentswithdifferentcnnsontwodatasetsarecompared toverifythegeneralizationcapabilitiesofourmethod sentencesgeneration datasetsandmetric generate accurate descriptive sentence remote ingimage long shorttermmemorynetwork experiment dataset remote sense image tioning ucm caption sydney caption controlthetransmissionofnetworkinformation evaluate performance different architecture sign solve long term dependency problem rnn differentcroppingscale theucm core lstm gate include forget gate vide consist class iamge inputgate andoutputgate class image pixel mationtodiscardthroughtheforgottengate thenbasedon resolution base sydney datum set input gate determine value go sydney date thetanhlayerisusedtogeneratecandidate forbothtwodataset fivesentence valuesthatcanbeaddedtothenetworkstate afterthat aregiventodescribeeachimage outputlayercangetthefinaloutputstatebyfiltering inaddition acommonlyusedmetricforimagecaptione time feature vector v transfer lstm t th word generate represent theprocessasfollow lation indetail itisabletoanalyzetheconsistencybetween w w n t n n gramoccurrencesincandidateandreferencesentence h v w t p setup t t whereh representsthehiddenstateoflstmattimet base encoder decoder framework train test t w isthecorrespondingwordinthecaption specially g method cnn architecture encoding t stage include inception fuction wecangettheprobabilityofthenextwordappeare inthedecodingprocess p thefinalgoalofthisstepistominimizethenegative eratetheeffectivesentence asforlstm thedimensionof t likelihoodfunctionoftargetsentences namelyloss spectively number layer lstm layer n logp w t t authorize license use limit university florida download march utc ieee xplore restriction apply classification ieee transaction geoscience remotesensing qu li tao lu deep semantic derstanding high resolution remote sense image international conference computer information white wave d green plant planeisstoppedatarrange neatly slap white flourish theairport road go sand beach banksoftheriver throughthem andoveragain tell neural image caption generator ieee conference computer vision pattern caption hochreiter schmidhuber long short term resultsandanalysis memory neuralcomputation datasetswithdifferentcnnarchitecture respectively qu li tao lu deep semantic ingthat derstanding high resolution remote sense image result find evaluation international conference computer information score ucm caption sydney caption cnn architecture get high select scale increase good cnn shi zou machine generate chitectureforencodingprocessbetweenallthearchitecture likelanguagedescriptionsforaremotesensingimage inexperiment theabundantexperimentalresultsprovethe ieeetransactionsongeoscienceandremotesensing effectiveness propose multi scale cropping nism el datum remote sense image caption conclusion tion ieee transaction geoscience remote sensing inthispaper weproposeamulti scalecroppingmechanism training extract advanced semantic feature krizhevsky sutskever hinton fromimagessothatitcangeneratemeaningfulsentencesfor task remote sense image captioning base work international conference neural popular encoder decoder framework cnn combine spatialpyramid datasetsshowtheeffectivenessoftheproposedmethod nition chineintelligence acknowledgment spatial work support national natural science pyramid enhancednetvladwithandweightedtriplet foundation china grant lossforplacerecognition naturalsciencefoundationofshaanxiprovinceundergrant fensescienceandtechnologyinnovation bleu method automatic evaluation machine lation association computational linguistic reference zhang ren sun deep residual ficationwithrecurrentattentionofvhrremotesensing learning image recognition ieee conference image ieeetransactionsongeoscienceandremote larizedlowrankrepresentationforhyperspectralimage authorize license use limit university florida download march utc ieee xplore restriction apply
